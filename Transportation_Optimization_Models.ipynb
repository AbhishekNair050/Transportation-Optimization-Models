{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "ON_45cV-0ujG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaewbeF_z1y4"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import linprog\n",
        "\n",
        "def solve_transportation_problem(costs, supplies, demands):\n",
        "    m = len(supplies)\n",
        "    n = len(demands)\n",
        "\n",
        "    # Create the cost matrix\n",
        "    c = np.array([costs[i][j] for i in range(m) for j in range(n)])\n",
        "\n",
        "    # Create the equality constraint matrix\n",
        "    A_eq = []\n",
        "    for i in range(m):\n",
        "        row = [int(j == i) for j in range(m)]\n",
        "        row.extend([0] * n)\n",
        "        A_eq.append(row)\n",
        "    for j in range(n):\n",
        "        row = [0] * m\n",
        "        row.extend([int(i == j) for i in range(n)])\n",
        "        A_eq.append(row)\n",
        "    b_eq = supplies + demands\n",
        "\n",
        "    # Create the inequality constraint matrices\n",
        "    A_ub = []\n",
        "    for i in range(m):\n",
        "        row = [1 if j == i else 0 for j in range(m)]\n",
        "        row.extend([0] * n)\n",
        "        A_ub.append(row)\n",
        "    b_ub = supplies\n",
        "\n",
        "    A_lb = []\n",
        "    for j in range(n):\n",
        "        row = [0] * m\n",
        "        row.extend([-1 if i == j else 0 for i in range(n)])\n",
        "        A_lb.append(row)\n",
        "    b_lb = [-demand for demand in demands]\n",
        "\n",
        "    res = linprog(-c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=(0, None))\n",
        "\n",
        "    return res.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "costs = [[15, 13], [15, 18]]\n",
        "supplies = [1600, 1600]\n",
        "demands = [1555, 1575]\n",
        "\n",
        "solution = solve_transportation_problem(costs, supplies, demands)\n",
        "print(solution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJZNyF3i0Sw_",
        "outputId": "cd7f921d-ef87-4273-ea19-d08ca9663a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1600. 1600. 1555. 1575.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "KMLDl7CD05vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import linprog\n",
        "import numpy as np\n",
        "\n",
        "def solve_multimodal_transportation_problem(cost_matrices, availabilities, demands, storages):\n",
        "    num_modes = len(cost_matrices)\n",
        "    m = len(availabilities[0])  # Number of suppliers\n",
        "    n = len(demands[0])         # Number of consumers\n",
        "\n",
        "    # Constructing the objective function coefficients\n",
        "    c = np.zeros((m * n * num_modes,))\n",
        "    for r in range(num_modes):\n",
        "        for i in range(m):\n",
        "            for j in range(n):\n",
        "                c[r * m * n + i * n + j] = cost_matrices[r][i][j]\n",
        "\n",
        "    # Constructing equality constraints\n",
        "    A_eq = []\n",
        "    b_eq = []\n",
        "    for r in range(num_modes):\n",
        "        for i in range(m):\n",
        "            for j in range(n):\n",
        "                eq_constraint = np.zeros((num_modes * m * n,))\n",
        "                eq_constraint[r * m * n + i * n + j] = 1\n",
        "                A_eq.append(eq_constraint)\n",
        "                b_eq.append(availabilities[r][i][j])\n",
        "    A_eq = np.array(A_eq)\n",
        "    b_eq = np.array(b_eq)\n",
        "\n",
        "    # Constructing inequality constraints\n",
        "    A_ub = np.zeros((n, num_modes * m * n))\n",
        "    b_ub = np.zeros((n,))\n",
        "    for r in range(num_modes):\n",
        "        for i in range(m):\n",
        "            for j in range(n):\n",
        "                A_ub[j, r * m * n + i * n + j] = 1\n",
        "                b_ub[j] = storages[r][i][j]\n",
        "\n",
        "    # Demand constraints\n",
        "    for j in range(n):\n",
        "        for r in range(num_modes):\n",
        "            for i in range(m):\n",
        "                A_ub = np.vstack((A_ub, np.zeros((1, num_modes * m * n))))\n",
        "                A_ub[-1, r * m * n + i * n + j] = 1\n",
        "                b_ub = np.concatenate((b_ub, [demands[0][j]]))\n",
        "\n",
        "    # Bounds\n",
        "    bounds = [(0, None)] * (m * n * num_modes)\n",
        "\n",
        "    # Solve the linear programming problem\n",
        "    res = linprog(c, A_eq=A_eq, b_eq=b_eq, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n",
        "\n",
        "    if res.success:\n",
        "        return res.x.reshape((num_modes, m, n))\n",
        "    else:\n",
        "        print(\"Optimization failed: \", res.message)\n",
        "        return None"
      ],
      "metadata": {
        "id": "634fYd4T05jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_matrices = [\n",
        "    [\n",
        "        [10, 15, 20],\n",
        "        [25, 18, 12],\n",
        "        [30, 25, 16]\n",
        "    ],\n",
        "    [\n",
        "        [12, 17, 22],\n",
        "        [27, 20, 14],\n",
        "        [32, 27, 18]\n",
        "    ]\n",
        "]\n",
        "\n",
        "availabilities = [\n",
        "    [\n",
        "        [50, 60, 70],\n",
        "        [40, 55, 65],\n",
        "        [30, 45, 55]\n",
        "    ],\n",
        "    [\n",
        "        [55, 65, 75],\n",
        "        [45, 60, 70],\n",
        "        [35, 50, 60]\n",
        "    ]\n",
        "]\n",
        "\n",
        "demands = [[30, 40, 50]]\n",
        "\n",
        "storages = [\n",
        "    [\n",
        "        [20, 25, 30],\n",
        "        [18, 23, 28],\n",
        "        [16, 21, 26]\n",
        "    ],\n",
        "    [\n",
        "        [22, 27, 32],\n",
        "        [20, 25, 30],\n",
        "        [18, 23, 28]\n",
        "    ]\n",
        "]\n",
        "\n",
        "solution = solve_multimodal_transportation_problem(cost_matrices, availabilities, demands, storages)\n",
        "print(solution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgvSYJf31d9m",
        "outputId": "cf52d4e5-58e9-4622-8cd0-74dc6188a0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization failed:  The problem is infeasible. (HiGHS Status 8: model_status is Infeasible; primal_status is At lower/fixed bound)\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4"
      ],
      "metadata": {
        "id": "ujUryP_g22Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiLayerPerceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiLayerPerceptron, self).__init__()\n",
        "        self.fc1 = nn.Linear(3, 5)  # Input layer (3 nodes) to hidden layer (5 nodes)\n",
        "        self.fc2 = nn.Linear(5, 6)  # Hidden layer (5 nodes) to output layer (6 nodes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def loss_function(output, target):\n",
        "    z1 = 0.7 * output[:, 0] + 0.95 * output[:, 1] + 0.95 * output[:, 2] + 0.2 * output[:, 3] + 0.25 * output[:, 4]\n",
        "    z2 = 0.35 * output[:, 0] + 0.45 * output[:, 1] + 0.48 * output[:, 2] + 0.44 * output[:, 3] + 0.5 * output[:, 4] + 0.6 * output[:, 5]\n",
        "    z3 = 0.4 * output[:, 0] + 0.5 * output[:, 1] + 0.6 * output[:, 2] + 0.5 * output[:, 3] + 0.5 * output[:, 4] + 0.8 * output[:, 5]\n",
        "    z = z1 + z2 + z3\n",
        "\n",
        "    return z.mean()\n",
        "\n",
        "# Create the neural network\n",
        "model = MultiLayerPerceptron()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(500):\n",
        "    # Generate input data\n",
        "    input_data = torch.randn(1, 3)  # Batch size of 1, input size of 3\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(input_data)\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss = loss_function(output, input_data)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print the loss every 100 epochs\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpLVKD6123g1",
        "outputId": "50bb374f-c312-44fa-8db7-5477b0dd43eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Loss: -15.099015235900879\n",
            "Epoch 100, Loss: -55.54655075073242\n",
            "Epoch 150, Loss: -182.94483947753906\n",
            "Epoch 200, Loss: -219.26260375976562\n",
            "Epoch 250, Loss: -273.86029052734375\n",
            "Epoch 300, Loss: -617.5321655273438\n",
            "Epoch 350, Loss: -1131.4298095703125\n",
            "Epoch 400, Loss: -1424.510986328125\n",
            "Epoch 450, Loss: -1985.369140625\n",
            "Epoch 500, Loss: -2718.721435546875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Example input data\n",
        "input_data = torch.tensor([[0.1, 0.2, 0.3]])\n",
        "\n",
        "# Create the neural network\n",
        "model = MultiLayerPerceptron()\n",
        "\n",
        "# Forward pass\n",
        "output = model(input_data)\n",
        "print(\"Output:\", output)\n",
        "\n",
        "# Calculate the loss\n",
        "loss = loss_function(output, input_data)\n",
        "print(\"Loss:\", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T98hhe073q4b",
        "outputId": "4d475a98-8505-415e-9a71-9609fd029a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[-0.2044,  0.0591, -0.1949,  0.2098,  0.1841,  0.0188]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Loss: -0.08412109315395355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generalized MLP solving the example problem done above"
      ],
      "metadata": {
        "id": "UYMK1ubrKW4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Define the MultiLayerPerceptron class\n",
        "class MultiLayerPerceptron(tf.keras.Model):\n",
        "    def __init__(self, input_dim, hidden_units, output_dim):\n",
        "        super(MultiLayerPerceptron, self).__init__()\n",
        "        self.fc1 = tf.keras.layers.Dense(hidden_units, activation='relu', input_dim=input_dim)\n",
        "        self.fc2 = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.fc1(inputs)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the loss function\n",
        "def loss_function(output, target):\n",
        "    loss = tf.reduce_mean(tf.square(output - target))\n",
        "    return loss\n",
        "\n",
        "# Sample input data\n",
        "cost_matrices = [\n",
        "    np.array([\n",
        "        [10, 15, 20],\n",
        "        [25, 18, 12],\n",
        "        [30, 25, 16]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [12, 17, 22],\n",
        "        [27, 20, 14],\n",
        "        [32, 27, 18]\n",
        "    ])\n",
        "]\n",
        "\n",
        "availabilities = [\n",
        "    np.array([\n",
        "        [50, 60, 70],\n",
        "        [40, 55, 65],\n",
        "        [30, 45, 55]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [55, 65, 75],\n",
        "        [45, 60, 70],\n",
        "        [35, 50, 60]\n",
        "    ])\n",
        "]\n",
        "\n",
        "demands = np.array([[30, 40, 50]])\n",
        "\n",
        "storages = [\n",
        "    np.array([\n",
        "        [20, 25, 30],\n",
        "        [18, 23, 28],\n",
        "        [16, 21, 26]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [22, 27, 32],\n",
        "        [20, 25, 30],\n",
        "        [18, 23, 28]\n",
        "    ])\n",
        "]\n",
        "\n",
        "# Concatenate all input data along the first axis\n",
        "input_data = np.concatenate(cost_matrices + availabilities + storages, axis=0)\n",
        "# Define model parameters\n",
        "input_dim = input_data.shape[-1]  # Dimension of input data\n",
        "hidden_units = 10  # Number of units in the hidden layer\n",
        "output_dim = 1  # Dimension of output data (for simplicity, we'll predict a single value)\n",
        "# Create the neural network\n",
        "model = MultiLayerPerceptron(input_dim, hidden_units, output_dim)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(500):\n",
        "    # Generate target data (replace this with your actual target data)\n",
        "    target_data = np.random.rand(1, output_dim)  # Example: random target data for illustration purposes\n",
        "\n",
        "    # Forward pass\n",
        "    with tf.GradientTape() as tape:\n",
        "        output = model(input_data)\n",
        "        loss = loss_function(output, target_data)\n",
        "\n",
        "    # Backward pass\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    # Print the loss every 50 epochs\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {loss.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWxJEc9vKY_h",
        "outputId": "6db704d2-d213-4bf1-abd5-7fffc8200a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Loss: 2.6839566230773926\n",
            "Epoch 100, Loss: 1.1491353511810303\n",
            "Epoch 150, Loss: 0.9161852598190308\n",
            "Epoch 200, Loss: 0.8773241639137268\n",
            "Epoch 250, Loss: 0.8803513050079346\n",
            "Epoch 300, Loss: 0.6596843004226685\n",
            "Epoch 350, Loss: 0.5993877053260803\n",
            "Epoch 400, Loss: 0.6293603181838989\n",
            "Epoch 450, Loss: 0.4517744779586792\n",
            "Epoch 500, Loss: 0.35894331336021423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate some test examples\n",
        "num_examples = 5\n",
        "test_examples = np.random.randn(num_examples, input_dim)  # Generating random test examples\n",
        "\n",
        "# Use the trained model for predictions\n",
        "for i, example in enumerate(test_examples):\n",
        "    prediction = model(example[np.newaxis, :])  # Forward pass through the model\n",
        "    print(f\"Test Example {i+1}: Input = {example}, Prediction = {prediction.numpy()[0][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbXyt9lMK3BR",
        "outputId": "aacd2928-6ea9-45b6-8fd3-8c0d37776d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Example 1: Input = [ 1.69966926  2.23410743 -0.20023704], Prediction = 0.3583950400352478\n",
            "Test Example 2: Input = [-1.68952781  1.68726399  0.20395108], Prediction = 0.46149539947509766\n",
            "Test Example 3: Input = [-1.39273888  0.88300849 -1.44773798], Prediction = 0.6194852590560913\n",
            "Test Example 4: Input = [-0.97206335  1.06258302  0.65960994], Prediction = 0.21457673609256744\n",
            "Test Example 5: Input = [ 0.67602809  0.54130242 -1.45443793], Prediction = -0.10116668045520782\n"
          ]
        }
      ]
    }
  ]
}